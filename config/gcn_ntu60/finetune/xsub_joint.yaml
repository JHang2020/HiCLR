work_dir: /mnt/netdisk/zhangjh/Code/AimCLR_loss/work_dir/NTU60/xsub/ABL/joint_MutalDDM_with4parallel_ablmask/finetune/
weights: /mnt/netdisk/zhangjh/Code/AimCLR_loss/work_dir/NTU60/xsub/ABL/joint_MutalDDM_with4parallel_ablmask/epoch300_model.pt
ignore_weights: [encoder_q.fc, encoder_k, queue]
#start_epoch: 60
#start_iter: 38200
# feeder
train_feeder: feeder.ntu_feeder.Feeder_finetune
train_feeder_args:
  data_path: /mnt/netdisk/linlilang/CrosSCLR/data/NTU60_frame50/xsub/train_position.npy
  label_path: /mnt/netdisk/linlilang/CrosSCLR/data/NTU-RGB-D/xsub/train_label.pkl
  data_view: joint
  norm: False
test_feeder: feeder.ntu_feeder.Feeder_finetune
test_feeder_args:
  data_path: /mnt/netdisk/linlilang/CrosSCLR/data/NTU60_frame50/xsub/val_position.npy
  label_path: /mnt/netdisk/linlilang/CrosSCLR/data/NTU-RGB-D/xsub/val_label.pkl
  data_view: joint
  norm: False

# model
model: net.aimclr.AimCLR
model_args:
  base_encoder: net.st_gcn.Model
  pretrain: False
  # feature_dim: 128
  # queue_size: 32768
  # momentum: 0.999
  # Temperature: 0.07
  # mlp: True
  in_channels: 3
  hidden_channels: 16
  hidden_dim: 256
  num_class: 60
  dropout: 0.5
  graph_args:
    layout: 'ntu-rgb+d'
    strategy: 'spatial'
  edge_importance_weighting: True

#optim
weight_decay: 0.0001
base_lr: 0.1
warm_up_epoch: 5
optimizer: SGD
step: [30, 55]
# training
device: [0]
batch_size: 64
test_batch_size: 64
num_epoch: 70

save_interval: -1
eval_interval: 5


