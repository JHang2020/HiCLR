work_dir: /mnt/netdisk/zhangjh/Code/AimCLR_loss/work_dir/NTU120/xsub/Transformer/motion_MutalDDM_with4parallel_ablmask02/
#weights: /mnt/netdisk/zhangjh/Code/AimCLR-main/work_dir/NTU60/xsub/motion_drop01add005mutalddm/epoch150_model.pt
#start_epoch: 150
exp_descri: MutalDDM_with4parallel_ablmask
# feeder
train_feeder: feeder.ntu_feeder.Feeder_triple
train_feeder_args:
  data_path: /mnt/netdisk/linlilang/CrosSCLR/data/NTU120_frame50/xsub/train_position.npy
  label_path: /mnt/netdisk/linlilang/CrosSCLR/data/NTU-RGB-D_120/xsub/train_label.pkl
  shear_amplitude: 0.5
  temperal_padding_ratio: 6
  mmap: True

# model
model: net.aimclr.AimCLR
model_args:
  base_encoder: net.dsta.DSTANet
  pretrain: True
  feature_dim: 128
  queue_size: 32768
  momentum: 0.999
  Temperature: 0.07
  mlp: True
  transformer: True

  in_channels: 3
  hidden_dim: 256

  num_point: 25
  num_frame: 50
  num_subset: 3
  num_person: 2
  glo_reg_s: True
  att_s: True
  glo_reg_t: False
  att_t: False
  dropout: 0
  attentiondrop: 0.5
  dropout2d: 0
  use_spatial_att: True
  use_temporal_att: False
  use_pet: True
  use_pes: True
  #fix_conv1: True
  #in_channels, out_channels, inter_channels, stride
  config: [ [32, 32, 16, 1], [32, 32, 16, 1],
            [32, 64, 16, 2], [64, 64, 16, 1],
            [64, 128, 32, 2], [128, 128, 32, 1],
            [128, 128, 32, 1], [128, 256, 32, 1],
  ]
  dropout_graph: 0.1
  add_graph: 0.05
  rep_ratio: 0.5

# optim
nesterov: False
weight_decay: 5e-4
base_lr: 0.1
optimizer: SGD
#warmup_epochs: 5
step: [250]

# training
device: [0]
batch_size: 128
test_batch_size: 128
num_epoch: 300
stream: 'motion'

mask_args:
  mask_ratio: 0.2
  person_num: 2
  joint_num: 25
  channel_num: 3

# nearest neighbor mining
topk: 1
mining_epoch: 150

# log
save_interval: 50
eval_interval: -1
